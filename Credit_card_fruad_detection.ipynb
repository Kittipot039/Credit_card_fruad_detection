{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d75a732-a063-404d-a401-619c0614eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data processing and visualization\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # Visualization\n",
    "import plotly.express as px # Visualization\n",
    "import seaborn as sns # Visualization\n",
    "\n",
    "# Libraries for preprocessing, model building, and MLflow\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# For Evalution we will use these library\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, confusion_matrix, \n",
    "    roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ea518-b7d9-4f6c-8feb-e61f61355c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset to a Pandas DataFrame\n",
    "credit_card_data = pd.read_csv('/Users/kittipot/Desktop/Credit_card_data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb410d-aa5d-4d75-8fbc-acb4908c5533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect dataset\n",
    "print(credit_card_data.head())\n",
    "print(credit_card_data.tail())\n",
    "# dataset informations\n",
    "print(credit_card_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c90bb1e-b04b-4d35-a8aa-7387e6bca55c",
   "metadata": {},
   "source": [
    "The dataset was retrieved from an open-source website, Kaggle.com. It contains data on transactions made in 2013 by European credit card users in two days only. Thedataset consists of 31 attributes and 284,808 rows. Twenty-eight attributes are numeric variables that, due to the confidentiality and privacy of the customers, have been transformed using PCA transformation; the three remaining attributes are ”Time”, which contains the elapsed seconds between the first and other transactions of each Attribute, ”Amount” is the amount of each transaction, and the final attribute “Class” which contains binary variableswhere “1” is a case of fraudulent transaction, and “0” is not as case of fraudulent transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4975032d-e681-4854-b603-fb0fe07ec4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of missing values in each column\n",
    "credit_card_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e18d12-0a4c-44d1-81b2-3d33490d71de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of legit transactions & fraudulent transactions\n",
    "credit_card_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c7690-d8a9-45e7-b4f5-f0153bd5a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"Time\" Columns\n",
    "credit_card_data = credit_card_data.drop(\"Time\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7982b00-d620-41ec-9404-b64946734da2",
   "metadata": {},
   "source": [
    "โดยทั่วไป Time ถูกลบออกเพราะมันไม่ได้มีส่วนช่วยที่ชัดเจนในการจำแนกการโกง และอาจเพิ่มความซับซ้อนโดยไม่จำเป็น."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9da2a3-ed70-49cc-8b06-b00d4906f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datatype from object to numeric\n",
    "print(credit_card_data['Amount'].dtype)\n",
    "credit_card_data['Amount'] = pd.to_numeric(credit_card_data['Amount'], errors='coerce')\n",
    "\n",
    "print(credit_card_data['Amount'].describe())\n",
    "print(credit_card_data['Amount'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a4716-18a5-4467-abfa-a7c8168a67f6",
   "metadata": {},
   "source": [
    "errors='coerce' ถูกใช้เพื่อป้องกันข้อผิดพลาดเมื่อแปลงข้อมูล และช่วยจัดการกับข้อมูลที่ไม่สามารถแปลงเป็นตัวเลขได้อย่างเหมาะสมโดยแปลงเป็น NaN.\n",
    ".unique() ใช้เพื่อดึง ค่าที่ไม่ซ้ำกัน ในคอลัมน์หรือ Series ซึ่งช่วยให้สามารถตรวจสอบข้อมูลที่ซ้ำซ้อนและค่าที่ผิดปกติได้ง่าย."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855366c-5937-41b8-b50d-3b807e2aa7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalizaing data\n",
    "credit_card_data['std_Amount'] = scaler.fit_transform(credit_card_data['Amount'].values.reshape (-1,1))\n",
    "\n",
    "# remove \"Amount\" Columns\n",
    "credit_card_data = credit_card_data.drop(\"Amount\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2bb6f-cd85-4377-899d-077f566582e7",
   "metadata": {},
   "source": [
    "เลือกใช้ StandardScaler เนื่องจากเราจะใช้อัลกอริธึมที่อ่อนไหวต่อขนาดของฟีเจอร์ (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9741390c-b9e1-4d05-88bd-c37a40e95482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn \n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b48f2b2-c7f9-4699-8185-98a905169950",
   "metadata": {},
   "source": [
    "เลือกใช้ RandomUnderSampler เนื่องจาก \n",
    "1.แก้ปัญหา Class Imbalance:\n",
    "ในปัญหา class imbalance ข้อมูลในคลาสที่มีจำนวนมากกว่าจะครอบงำโมเดล ส่งผลให้โมเดลให้ความสำคัญกับคลาสที่มีตัวอย่างเยอะ และละเลยคลาสที่มีตัวอย่างน้อย\n",
    "RandomUnderSampler ลดจำนวนตัวอย่างในคลาสที่มีมากเกินไป (majority class) ให้เท่ากับคลาสที่มีน้อยกว่า (minority class) เพื่อให้เกิดความสมดุล\n",
    "2.เพิ่มประสิทธิภาพโมเดล:\n",
    "โมเดลที่เทรนกับชุดข้อมูลที่สมดุลมักจะมีประสิทธิภาพดีกว่าในแง่ของเมตริก เช่น F1 Score, Recall, Precision โดยเฉพาะสำหรับคลาสที่มีจำนวนน้อย\n",
    "3.ลดเวลาในการประมวลผล:\n",
    "เมื่อคลาสที่มีจำนวนมากถูกลดขนาดลง จะลดขนาดของชุดข้อมูลโดยรวม ทำให้การเทรนโมเดลเร็วขึ้นและใช้ทรัพยากรน้อยลง\n",
    "4.การทำงานง่ายและตรงไปตรงมา:\n",
    "RandomUnderSampler เป็นวิธีที่ง่ายและเร็วที่สุดในการสร้างความสมดุล โดยเพียงแค่เลือกตัวอย่างจาก majority class แบบสุ่มจนกระทั่งจำนวนตัวอย่างในทุกคลาสเท่ากัน\n",
    "ไม่มีพารามิเตอร์ที่ซับซ้อนในการตั้งค่า"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf88ffd-aec4-4842-91a6-7b232043689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feature & Target\n",
    "X = credit_card_data.drop(columns=[\"Class\"])\n",
    "Y = credit_card_data[\"Class\"]\n",
    "\n",
    "# Undersample\n",
    "X_under, Y_under = undersample.fit_resample(X, Y)\n",
    "test = pd.DataFrame(Y_under, columns = ['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127737de-9807-4456-9cd1-870efac340b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing undersampling results\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(13,4.5))\n",
    "sns.countplot(x=\"Class\", data=credit_card_data, ax=axs[0])\n",
    "sns.countplot(x=\"Class\", data=test, ax=axs[1])\n",
    "\n",
    "fig.suptitle(\"Class repartition before and after undersampling\")\n",
    "a1=fig.axes[0]\n",
    "a1.set_title(\"Before\")\n",
    "a2=fig.axes[1]\n",
    "a2.set_title(\"After\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0a2c12-c97d-4395-b5c8-13fdfa52e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train & test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, Y_under, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ba3b3-566b-40c6-8ef9-3203dbb063ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use mlflow manage model life cycle\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Create & train model\n",
    "    model = SVC(probability=True, random_state=2)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict results\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Save parameters & metrics in MLflow\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "\n",
    "    # Create input_example\n",
    "    input_example = X_test.iloc[:5]  # Use 5 rows from X_test\n",
    "\n",
    "    # Create signature\n",
    "    signature = infer_signature(X_test, model.predict(X_test))\n",
    "\n",
    "    # Save trained model in MLflow\n",
    "    mlflow.sklearn.log_model(model, \"SVC_Model\", input_example=input_example, signature=signature)\n",
    "\n",
    "    print(f\"Model logged with accuracy: {accuracy}\")\n",
    "    print(f\"Model logged with precision: {precision}\")\n",
    "    print(f\"Model logged with recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2245a8-a878-44f5-a3e7-9116787f7851",
   "metadata": {},
   "source": [
    "1. Accuracy: 0.9459 (~94.6%)\n",
    "Accuracy คือสัดส่วนของจำนวนการทำนายที่ถูกต้อง (ทั้งคลาสโกงและไม่โกง) ต่อจำนวนตัวอย่างทั้งหมดในชุดข้อมูล.\n",
    "\n",
    "ค่า 0.9459 หมายความว่า โมเดลสามารถทำนายได้ถูกต้องประมาณ 94.6% ของข้อมูลทั้งหมด.\n",
    "อย่างไรก็ตาม Accuracy อาจไม่ใช่ตัวชี้วัดที่ดีที่สุดในกรณีที่ชุดข้อมูลมีการกระจายของคลาสไม่สมดุล (เช่น มีธุรกรรมที่ไม่โกงมากกว่าธุรกรรมที่โกง) ซึ่งอาจทำให้โมเดลมีการทำนายคลาสที่ไม่โกงได้ดีมากกว่า.\n",
    "\n",
    "2. Precision: 0.9894 (~98.9%)\n",
    "Precision คือความแม่นยำของโมเดลในการทำนายคลาส \"โกง\" (positive class)\n",
    "ค่า 0.9894 หมายความว่า 98.9% ของธุรกรรมที่โมเดลทำนายว่าเป็น \"โกง\" เป็นการทำนายที่ถูกต้อง (จริง ๆ แล้วเป็นการโกง).\n",
    "การมีค่า precision ที่สูงเช่นนี้หมายความว่าโมเดลไม่ค่อยทำนายว่าธุรกรรมที่ไม่โกงเป็นการโกง (false positives ต่ำ).\n",
    "\n",
    "3. Recall: 0.8611 (~86.1%)\n",
    "Recall คือความสามารถของโมเดลในการระบุธุรกรรมที่โกงทั้งหมด (True Positives) จากทุก ๆ ธุรกรรมที่โกง (รวมทั้ง False Negatives). \n",
    "ค่า 0.8611 หมายความว่าโมเดลสามารถทำนายได้ 86.1% ของธุรกรรมที่โกง (แต่ยังมีบางธุรกรรมที่โกงไม่ได้รับการทำนายเป็นการโกง).\n",
    "Recall ที่สูงเป็นการบ่งชี้ว่าโมเดลมีประสิทธิภาพในการค้นหาธุรกรรมที่โกง (ไม่ทำนายผิดเป็นคลาสที่ไม่โกง)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4cb11d-22f7-4ea7-b9fd-27d26412e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "matrix_svm = confusion_matrix(y_test, y_pred)\n",
    "# Create confusion matrix dataframe\n",
    "cm_svm = pd.DataFrame(matrix_svm, index=['not_fraud', 'fraud'], columns=['not_fraud', 'fraud'])\n",
    "\n",
    "# Visualize confusion matrix by heatmap\n",
    "sns.heatmap(cm_svm, annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\n",
    "plt.title(\"Confusion Matrix SVM\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107cd86b-6068-4211-a647-ac7116dd6a27",
   "metadata": {},
   "source": [
    "จากกราฟจะเห็นว่า\n",
    "TP = 187 FN = 1           TP:เป็นธุรกรรมไม่โกงและโมเดลทำนายเป็นไม่โกง        FN:เป็นธุรกรรมไม่โกงและโมเดลทำนายเป็นโกง \n",
    "FP = 15  TN = 93          FP: เป็นธุรกรรมโกงและโมเดลทำนายเป็นไม่โกง         TN:เป็นธุรกรรมโกงและโมเดลทำนายเป็นโกง "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f278c6f-a1be-4b7c-abf4-856910e88362",
   "metadata": {},
   "source": [
    "ต่อไปเราจะทำการคำนวณค่าAUCของModel SVM โดยใช้ ROC Curve ซึ่งเป็นเครื่องมือวัดประสิทธิภาพของโมเดลการทำนายแบบสองคลาส (binary classification) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ca196-3d1e-48b0-83bf-c2d2f1a3fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find fpr,tpr & AUC\n",
    "y_pred_svm_proba = model.predict_proba(X_test)[::,1]\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test,  y_pred_svm_proba)\n",
    "auc_svm = roc_auc_score(y_test, y_pred_svm_proba)\n",
    "print(\"AUC SVM :\", auc_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba243d97-de99-4049-89d6-a619b2c01036",
   "metadata": {},
   "source": [
    "1.y_pred_svm_proba = model.predict_proba(X_test)[::,1]\n",
    "การคำนวณ: ใช้เมธอด predict_proba จากโมเดล SVM เพื่อคาดการณ์ความน่าจะเป็น (probability) ของแต่ละคลาสสำหรับข้อมูลทดสอบ (X_test):\n",
    "model.predict_proba(X_test) คืนค่าเป็น array สองมิติ ที่แสดงความน่าจะเป็นของคลาสที่เป็น 0 และ 1\n",
    "[::,1] เลือกเฉพาะค่าความน่าจะเป็นของคลาส 1 (การฉ้อโกง)\n",
    "ผลลัพธ์: y_pred_svm_proba จะเป็น array ที่มีค่าความน่าจะเป็นของคลาส 1 สำหรับข้อมูลทดสอบ\n",
    "2.fpr_svm, tpr_svm, _ = metrics.roc_curve(y_test, y_pred_svm_proba)\n",
    "การคำนวณ: ใช้ฟังก์ชัน roc_curve จากไลบรารี sklearn.metrics เพื่อสร้างค่า:\n",
    "tpr_svm (True Positive Rate):  TP/TP+FN\n",
    "fpr_svm (False Positive Rate): FP/FP+TN\n",
    "3.auc_svm = metrics.roc_auc_score(y_test, y_pred_svm_proba)\n",
    "การคำนวณ: ใช้ฟังก์ชัน roc_auc_score จาก sklearn.metrics เพื่อคำนวณค่าพื้นที่ใต้โค้ง ROC (AUC - Area Under the Curve)\n",
    "AUC เป็นตัวชี้วัดประสิทธิภาพของโมเดล\n",
    "ค่า AUC จะอยู่ในช่วง 0 ถึง 1\n",
    "1.0 หมายถึงโมเดลสมบูรณ์แบบ\n",
    "0.5 หมายถึงโมเดลแย่เท่าการสุ่มเดา"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7545ba6f-a41b-4d94-a51f-12c919d6edf4",
   "metadata": {},
   "source": [
    "ROC (Receiver Operating Characteristic) และ AUC (Area Under the Curve) เป็นเครื่องมือที่มีความสัมพันธ์กันในการประเมินประสิทธิภาพของโมเดลการจำแนกประเภท (classification)\n",
    "ความสัมพันธ์ระหว่าง ROC และ AUC:\n",
    "ROC Curve แสดง การกระจายตัว ของ TPR และ FPR ภายใต้ค่า threshold ที่เปลี่ยนแปลง\n",
    "AUC คือ การสรุปผล ของ ROC Curve ในรูปของตัวเลขเดียว เพื่อบ่งบอกประสิทธิภาพของโมเดลในทุก ๆ threshold\n",
    "กล่าวง่าย ๆ:\n",
    "ROC คือกราฟแสดงการวัดประสิทธิภาพ\n",
    "AUC คือค่าตัวเลขที่ได้จาก ROC เพื่อวัดว่าโมเดลดีแค่ไหน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d27285-1298-4f9e-8fa2-b2574768783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ROC Curve\n",
    "plt.plot(fpr_svm,tpr_svm,label=\"SVM, auc={:.3f})\".format(auc_svm))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('SVM ROC curve')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef963f2f-057f-4b74-b7c1-3abc2cb0995d",
   "metadata": {},
   "source": [
    "1.plt.plot(fpr_svm, tpr_svm, label=\"SVM, auc={:.3f})\".format(auc_svm))\n",
    "การทำงาน:\n",
    "สร้างกราฟ ROC Curve โดยใช้ค่า False Positive Rate (FPR) และ True Positive Rate (TPR) ของโมเดล SVM\n",
    "ใช้ label เพื่อแสดงคำอธิบายกราฟ โดยรวมค่าคำนวณ AUC (พื้นที่ใต้โค้ง ROC) ลงไปในรูปแบบตัวเลข 3 ตำแหน่งทศนิยม ({:.3f})\n",
    "ผลลัพธ์:\n",
    "เส้น ROC Curve ที่มีป้ายกำกับ เช่น \"SVM, auc=0.976\"\n",
    "2.plt.plot([0, 1], [0, 1], 'k--')\n",
    "การทำงาน:\n",
    "เพิ่มเส้นทแยงมุมเส้นประ ('k--' หมายถึงเส้นสีดำและแบบ dashed line) ซึ่งแทนกราฟของโมเดลที่ไม่มีประสิทธิภาพ (AUC = 0.5)\n",
    "เส้นนี้เริ่มจาก (0,0) ถึง (1,1) ซึ่งแสดงว่าค่า FPR และ TPR เพิ่มขึ้นพร้อมกัน\n",
    "ผลลัพธ์:\n",
    "เส้นทแยงมุมเพื่อใช้เป็นเกณฑ์เปรียบเทียบกับ ROC Curve ของโมเดล\n",
    "3.plt.legend(loc=4)\n",
    "การทำงาน:\n",
    "แสดงป้ายคำอธิบายกราฟ (legend) โดยตำแหน่งของป้ายกำกับถูกตั้งค่าเป็น loc=4 ซึ่งหมายถึงมุมขวาล่างของกราฟ\n",
    "ผลลัพธ์ที่ได้จากโค้ด\n",
    "กราฟ ROC Curve ของโมเดล SVM จะถูกสร้างขึ้น\n",
    "มีเส้น ROC ที่บ่งบอกประสิทธิภาพของโมเดล และมี AUC แสดงในป้ายกำกับ\n",
    "เส้นทแยงมุมเส้นประใช้เปรียบเทียบกับเส้น ROC ของโมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b967133-d1ca-48f8-90d6-b5947c139c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Precision & recall\n",
    "svm_precision, svm_recall, _ = precision_recall_curve(y_test, y_pred_svm_proba)\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test) # Find Precision of no skill model\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', color='black', label='No Skill')\n",
    "plt.plot(svm_recall, svm_precision, color='orange', label='SVM')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59228945-e24f-4ec0-9c79-1b079e42eece",
   "metadata": {},
   "source": [
    "การใช้ No Skill Model\n",
    "การเปรียบเทียบประสิทธิภาพของโมเดล:\n",
    "ใช้ No Skill Model เป็นตัวอ้างอิงพื้นฐาน (baseline) เพื่อประเมินประสิทธิภาพของโมเดลที่เราพัฒนาขึ้น เช่น\n",
    "หากโมเดลที่พัฒนาใหม่ทำงานไม่ดีเกิน No Skill Model แสดงว่าโมเดลของเรายังไม่ดีพอ\n",
    "หากโมเดลที่พัฒนาใหม่ทำงานดีกว่า No Skill Model แสดงว่าโมเดลมีความสามารถในการแยกแยะข้อมูลได้\n",
    "การตรวจสอบการทำงานของโมเดล:\n",
    "เมื่อใช้ No Skill Model เป็นจุดเริ่มต้น เปรียบเทียบกับโมเดลจริงจะช่วยให้เห็นได้ชัดว่าประสิทธิภาพของโมเดลที่พัฒนามานั้นเพิ่มขึ้นมากแค่ไหน\n",
    "\n",
    "ยิ่ง Precision และ Recall สูงมากขึ้น (เส้นโค้งเข้าใกล้มุมขวาบน) หมายถึงโมเดลมีประสิทธิภาพสูง"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
